以下是 **Llama 系列** 相关的论文及其对应的 **arXiv 链接**，涵盖基础模型、改进版本及相关研究：

---

### **1. 基础模型**
1. **LLaMA: Open and Efficient Foundation Language Models**  
   - **标题**: *LLaMA: Open and Efficient Foundation Language Models*  
   - **作者**: Hugo Touvron 等（Meta AI）  
   - **arXiv链接**: [arXiv:2302.13971](https://arxiv.org/abs/2302.13971)  
   - **内容**: 介绍了 LLaMA 7B-65B 参数模型，使用公开数据集训练，性能优于 GPT-3 和 Chinchilla。  

2. **LLaMA 2: Open Foundation and Fine-Tuned Chat Models**  
   - **标题**: *Llama 2: Open Foundation and Fine-Tuned Chat Models*  
   - **arXiv链接**: [arXiv:2307.09288](https://arxiv.org/abs/2307.09288)  
   - **内容**: 介绍 LLaMA 2 及 LLaMA 2-Chat，优化了 RLHF（人类反馈强化学习），在安全性和性能上超越前代。  

---

### **2. 改进与扩展**
3. **LLaMA Pro: Progressive LLaMA with Block Expansion**  
   - **标题**: *LLaMA Pro: Progressive LLaMA with Block Expansion*  
   - **arXiv链接**: [arXiv:2401.02415](https://arxiv.org/abs/2401.02415)  
   - **内容**: 提出块扩展方法，使 LLaMA 2-7B 扩展至 8.3B，增强代码和数学能力。  

4. **Xwin-Math: Unlocking LLaMA-2-7B's Math Potential with Synthetic Data**  
   - **标题**: *Common 7B Language Models Already Possess Strong Math Capabilities*  
   - **arXiv链接**: [arXiv:2403.04706](https://arxiv.org/abs/2403.04706)  
   - **内容**: 通过合成数据微调 LLaMA-2-7B，显著提升数学推理能力。  

5. **Self-Rewarding Language Models (Meta & NYU)**  
   - **标题**: *Self-Rewarding Language Models*  
   - **arXiv链接**: [arXiv:2401.10020](https://arxiv.org/abs/2401.10020)  
   - **内容**: 让 LLaMA 2-70B 自我迭代优化，超越 GPT-4 0613 和 Claude 2。  

---

### **3. 安全与优化**
6. **PUMA: Secure Inference of LLaMA-7B in Five Minutes**  
   - **标题**: *PUMA: Secure Inference of LLaMA-7B in Five Minutes*  
   - **arXiv链接**: [arXiv:2307.12533](https://arxiv.org/abs/2307.12533)  
   - **内容**: 提出 MPC（安全多方计算）框架，5 分钟内完成 LLaMA-7B 的安全推理。  

---

### **完整资源**
- **Meta LLaMA 官方 GitHub**: [https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama)  
- **LLaMA Pro 项目**: [https://github.com/TencentARC/LLaMA-Pro](https://github.com/TencentARC/LLaMA-Pro)  

如需更详细的论文内容或特定研究方向，可访问上述链接或 Meta AI 的官方发布渠道。